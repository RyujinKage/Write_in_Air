{"cells":[{"cell_type":"code","metadata":{"id":"SGlGdi50y_yK","colab_type":"code","colab":{}},"source":["!unzip -uq \"PATH/new_data.zip\" -d \".\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9IMZL1Kz4tQ","colab_type":"code","outputId":"48ac86d1-5a8e-4273-8496-950efff75dc1","executionInfo":{"status":"ok","timestamp":1589716892909,"user_tz":-330,"elapsed":9362,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras import backend as K\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n","from keras.optimizers import Adam\n","from keras.callbacks import LearningRateScheduler\n","from keras import models"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"HlkWv-gv0Kjd","colab_type":"code","colab":{}},"source":["# dimensions of our images.\n","img_width, img_height = 32, 32\n","\n","train_data_dir = 'train'\n","validation_data_dir = 'validation'\n","\n","epochs = 2\n","batch_size = 160\n","\n","if K.image_data_format() == 'channels_first':\n","    input_shape = (1, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K54Gwqae0So7","colab_type":"code","outputId":"39765b01-3ee8-4b67-9b47-cace40ab2f67","executionInfo":{"status":"ok","timestamp":1589716892913,"user_tz":-330,"elapsed":9341,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"source":["model = Sequential()\n","\n","model.add(Conv2D(filters = 8, kernel_size = (3, 3), activation='relu',\n","                 input_shape = (32,32,3)))\n","\n","model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPool2D(strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n","model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","\n","model.add(MaxPool2D(strides=(2,2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(1024, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(12, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 30, 30, 8)         224       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 28, 28, 16)        1168      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 28, 28, 16)        64        \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 12, 12, 32)        4640      \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 10, 10, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 5, 5, 32)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 800)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               410112    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              525312    \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 12)                12300     \n","=================================================================\n","Total params: 963,196\n","Trainable params: 963,100\n","Non-trainable params: 96\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5yenA7CU0eL1","colab_type":"code","outputId":"1d4485e5-9b89-4d0d-aef1-b5a639d95e5f","executionInfo":{"status":"ok","timestamp":1589716894036,"user_tz":-330,"elapsed":10450,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","# this is the augmentation configuration we will use for training\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2)\n","\n","# this is the augmentation configuration we will use for testing:\n","# only rescaling\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 34049 images belonging to 12 classes.\n","Found 14599 images belonging to 12 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tio8RE7t0pl3","colab_type":"code","outputId":"3c0ce3d9-f52e-450a-948d-c4b7c8628a3e","executionInfo":{"status":"ok","timestamp":1587352749758,"user_tz":-330,"elapsed":10954474,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["from keras.callbacks import ModelCheckpoint\n","filepath=\"weights.best.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n"," \n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=34049,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=14599,\n","    callbacks=callbacks_list)\n"," \n","model.save_weights('final_weights.h5')\n","model.save('final_model_weight.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","34049/34049 [==============================] - 12832s 377ms/step - loss: 0.0774 - accuracy: 0.9835 - val_loss: 1.3898e-05 - val_accuracy: 0.9907\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.99068, saving model to /content/drive/My Drive/Colab Notebooks/model3/weights.best.hdf5\n","Epoch 2/2\n","20927/34049 [=================>............] - ETA: 1:16:48 - loss: 0.0683 - accuracy: 0.9874"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WP8z4IoPQt0J","colab_type":"code","outputId":"cd7da096-29d5-4414-9bbb-ae8719266c79","executionInfo":{"status":"ok","timestamp":1589764083082,"user_tz":-330,"elapsed":11536,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":714}},"source":["# load and evaluate a saved model\n","from numpy import loadtxt\n","from keras.models import load_model\n","\n","# load model\n","model = load_model('final_model_weight.h5')\n","# summarize model.\n","model.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 30, 30, 8)         224       \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 28, 28, 16)        1168      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 28, 28, 16)        64        \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 14, 14, 16)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 12, 12, 32)        4640      \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 10, 10, 32)        128       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 5, 5, 32)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 800)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               410112    \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              525312    \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 12)                12300     \n","=================================================================\n","Total params: 963,196\n","Trainable params: 963,100\n","Non-trainable params: 96\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ltA3cBC2UoHP","colab_type":"code","outputId":"7e898139-d79c-4cf3-ffa2-81ceeccc278e","executionInfo":{"status":"ok","timestamp":1589764445241,"user_tz":-330,"elapsed":3022,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# load dataset\n","from keras.preprocessing.image import ImageDataGenerator\n","validation_data_dir = 'validation'\n","img_width, img_height = 32, 32\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","epochs = 2\n","batch_size = 160\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='categorical')\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 14599 images belonging to 12 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TKd51a87VYmn","colab_type":"code","outputId":"95d45877-9f95-4bf0-a017-12c0cbbf7650","executionInfo":{"status":"ok","timestamp":1589764516556,"user_tz":-330,"elapsed":12658,"user":{"displayName":"Rajendra Prajapat","photoUrl":"","userId":"07548500344351187217"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# evaluate the model\n","score = model.evaluate(validation_generator, verbose=0)\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["accuracy: 99.23%\n"],"name":"stdout"}]}],"metadata":{"colab":{"name":"train_digit_operator.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}